import numpy as np
from skimage.color import rgb2lab
from skimage.feature import local_binary_pattern, SIFT
from skimage.measure import regionprops
from sklearn.svm import OneClassSVM

from util import bbox_to_axis_aligned_bbox, get_search_region, superpixel_image


def extract_colour_histogram(image, labels, n_bins=8, use_lab=False):
    ih, iw, _ = image.shape
    n_labels = labels.max() + 1

    _range = np.array(
        [[0, 256], [0, 256], [0, 256]], dtype="float"
    )  # for rgb histograms

    if use_lab:
        image = rgb2lab(image)
        _range[:] = [
            [0, 100],
            [-500 * 25 / 29, 500 * 25 / 29],
            [-200 * 25 / 29, 200 * 25 / 29],
        ]

    hist = np.zeros((n_labels, n_bins ** 3))

    mask = np.zeros((ih, iw), dtype="bool")

    for i in range(n_labels):
        mask[:] = labels == i
        yy, xx = mask.nonzero()

        pixels = image[yy, xx, :]

        hist[i, :] = np.histogramdd(sample=pixels, bins=n_bins, range=_range)[0].flat

    return hist


def extract_RGB_SIFT_features(image, labels):
    n_sp = np.max(labels) + 1
    feat_descs = np.zeros((n_sp, 128 * 3))
    img_superpixel = np.zeros_like(labels, dtype="int")

    # extract SIFT features for each colour channel
    f = np.empty((3,), dtype="object")
    d = np.empty((3,), dtype="object")

    for n in range(3):
        sift = SIFT()
        sift.detect_and_extract(image[..., n])
        f[n] = sift.keypoints
        d[n] = sift.descriptors

    r = np.arange(f[0].shape[0])  # indices of all features

    # find feature desc nearest to centroid and fill in for each channel
    for i in range(n_sp):
        # get centroid of i'th superpixel
        img_superpixel[:] = labels == i
        c = regionprops(img_superpixel)[0].centroid

        # find nearest sift feature location to the centroid
        D = np.sum((f[0] - c) ** 2, axis=1)
        d_amin = D.argmin()

        # see how many are equally close
        equal_mask = D == D[d_amin]
        n_equal = np.count_nonzero(equal_mask)

        # if no draws, pick closest, else randomly pick from the equally closest
        idx = d_amin if n_equal == 1 else np.random.choice(r[equal_mask])

        # fill in the feature vector for each image channel
        for n in range(3):
            # pick out which bit of the feature vector we're in and fill it in
            j, k = n * 128, (1 + n) * 128
            feat_descs[i, j:k] = d[n][idx, :]

    return feat_descs


def extract_RGB_LBP_features(image, labels, size=5, P=8, R=2):
    n_sp = np.max(labels) + 1
    hs = size // 2
    img_superpixel = np.zeros_like(labels, dtype="int")

    # calculate lbp for entire region
    lbp_img = np.empty((3,), dtype="object")
    for d in range(3):
        lbp_img[d] = local_binary_pattern(image[..., d], P=P, R=R, method="uniform")

    feat_desc_size = P + 1

    feat_descs = np.zeros((n_sp, feat_desc_size * 3))

    for i in range(n_sp):
        # get centroid of i'th superpixel
        img_superpixel[:] = labels == i
        cy, cx = [
            np.rint(x).astype("int") for x in regionprops(img_superpixel)[0].centroid
        ]

        # extract lbp values in sizeXsize region centred on the centroid
        x0, y0, x1, y1 = cx - hs, cy - hs, cx + hs + 1, cy + hs + 1

        # clip to boundaries of image
        x0 = 0 if x0 < 0 else x0
        y0 = 0 if y0 < 0 else y0
        x1 = image.shape[1] - 1 if x1 > image.shape[1] - 2 else x1
        y1 = image.shape[0] - 1 if y1 > image.shape[0] - 2 else y1

        # fill in the feature vector for each image channel
        for d in range(3):
            j, k = d * feat_desc_size, (1 + d) * feat_desc_size
            patch = lbp_img[d][y0:y1, x0:x1].flat

            fv = np.histogram(
                patch,
                bins=np.arange(0, feat_desc_size + 1),
                range=(0, feat_desc_size + 1),
            )[0]
            feat_descs[i, j:k] = fv

    return feat_descs


def perform_ocsvm_segmentation(
    image,
    bbox,
    gamma=-19,
    nu=0.250,
    crop_ratio=2,
    feature_name="RGB",
    return_crop_region=False,
):
    """
    Performs segmentation using a One-Class SVM and RGB/LAB/SIFT/LBP features.

    Arguments:
        image              = MxNxD numpy array containing the image to be segmented.
        bbox               = array containing bounding box of the form
                             [x0, y0, x1, y1, x2, y2, x3, y3].
        gamma              = RBF kernelâ€™s length-scale - 2**gamma
        nu                 = upper bound on the assumed number of outliers in
                             the training data - (0, 1)
        crop_ratio         = factor to multiply the axis-aligned version of the
                             bbox by to denote size of area to crop image to.
        feature_name       = Feature descriptor to use, valid options are:
                             'RGB', 'LAB', 'SIFT', 'LBP'.
        return_crop_region = boolean, if True the function also returns a
                             vector containing the region used for superpixeling.

    Output:
        image_mask       = boolean mask containing True for pixels labelled as
                           belonging to the object, and False otherwise.
        [x0, y0, x1, y1] = start/end points for respective image dimensions used
                           for superpixeling (OPTIONAL)
    """

    bbox = np.array(bbox, dtype="float")
    if bbox.shape != (8,):
        raise ValueError(
            "Bounding box must be of the form [x0, y0, x1, y1, x2, y2, x3, y3]."
        )

    if feature_name not in ["RGB", "LAB", "SIFT", "LBP"]:
        raise ValueError("Features must be one of: RGB, LAB, SIFT, or LBP.")

    if len(image.shape) != 3:
        raise ValueError("Image must be 3D with last dimension presumed to be RGB.")

    bbox_aa = bbox_to_axis_aligned_bbox(bbox)

    # get coords of region to crop
    c_x0, c_y0, c_x1, c_y1 = get_search_region(bbox_aa, image, crop_ratio)

    # crop image and move bbox to cropped image coords
    c_image = image[c_y0:c_y1, c_x0:c_x1].copy()
    c_bbox = bbox.copy()
    c_bbox[::2] -= c_x0
    c_bbox[1::2] -= c_y0

    # superpixel cropped region
    segments, sp_labels = superpixel_image(c_image, c_bbox)

    # extract features
    if feature_name == "RGB":
        features = extract_colour_histogram(c_image, segments, use_lab=False)
    elif feature_name == "LAB":
        features = extract_colour_histogram(c_image, segments, use_lab=True)
    elif feature_name == "SIFT":
        features = extract_RGB_SIFT_features(c_image, segments)
    else:
        features = extract_RGB_LBP_features(c_image, segments)

    # split into train/test
    f_train = features[~sp_labels, :]  # 100% outside bbox
    f_test = features[sp_labels, :]  # overlapping/inside bbox

    # standardise using training data's mean + standard deviation
    mn, std = np.mean(f_train, axis=0), np.std(f_train, axis=0)
    f_train -= mn[np.newaxis, :]
    f_test -= mn[np.newaxis, :]
    f_train[:, std != 0] /= std[np.newaxis, std != 0]
    f_test[:, std != 0] /= std[np.newaxis, std != 0]

    # train classifier
    clf = OneClassSVM(kernel="rbf", gamma=2.0 ** gamma, nu=nu)
    clf.fit(f_train, np.ones(f_train.shape[0]))

    # predict and convert into 1 = inside bbox, 0 = outside labels
    pred = clf.predict(f_test)  # predicts 1 outside bbox, -1 otherwise
    pred[pred == -1] = 0  # set so 0 = not outside bbox
    pred = ~np.array(
        pred, dtype="bool"
    )  # cast to boolean and inverse (so True = inside bbox)

    # create mask of area classified as belonging to the object
    mask = np.zeros(c_image.shape[:2], dtype="bool")

    for i, sp_no in enumerate(np.arange(len(sp_labels))[sp_labels == True]):
        if pred[i]:
            mask |= segments == sp_no

    image_mask = np.zeros(image.shape[:2], dtype="bool")
    image_mask[c_y0:c_y1, c_x0:c_x1] = mask

    if return_crop_region:
        return image_mask, [c_x0, c_y0, c_x1, c_y1]

    return image_mask


if __name__ == "__main__":
    import matplotlib.pyplot as plt
    from PIL import Image

    # apply segmentation to gymnastics4 image (from VOT2016 data set)
    image = Image.open("images/gymnastics4_00000233.jpg")
    image = np.array(image)
    bbox = np.array([376.33, 262.1, 461.85, 205.38, 500.77, 264.05, 415.25, 320.77])

    mask, [x0, y0, x1, y1] = perform_ocsvm_segmentation(
        image, bbox, feature_name="LAB", return_crop_region=True
    )

    # remove pixels from image that are labelled as background
    image_masked = image.copy()
    for d in range(3):
        image_masked[..., d].flat[~mask.ravel()] = 255

    # display original image, segmentation, and segmented image
    images = [image[y0:y1, x0:x1, :], mask[y0:y1, x0:x1], image_masked[y0:y1, x0:x1]]
    titles = ["Original image", "Segmentation", "Segmented image"]

    bbox_pts = np.concatenate((np.reshape(bbox, (-1, 2)), bbox[:2][np.newaxis, :]))
    bbox_pts -= [x0, y0]

    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))
    for image, title, a in zip(images, titles, ax):
        a.imshow(image)
        for i in range(4):
            a.plot(bbox_pts[i : i + 2, 0], bbox_pts[i : i + 2, 1], "c-", lw=2)
        a.set_title(title)
        a.axis("off")
    plt.show()
